{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0a6f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput: a pdf file of a book or something\\noutput: txt file with tokenized text\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input: a pdf file of a book or something\n",
    "output: txt file with tokenized text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33d86e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6efd5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9735474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove standalone line numbers and bullet points\n",
    "    text = re.sub(r'^\\d+\\.\\s+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^\\*\\s+', '', text, flags=re.MULTILINE)  # if bullet points exist\n",
    "\n",
    "    # Remove all lines that don't contain a lowercase letter (likely headings or titles)\n",
    "    text = re.sub(r'^(?![a-z]).*\\n', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Replace multiple newlines with just one (after the previous removals)\n",
    "    text = re.sub(r'\\n\\n+', '\\n', text)\n",
    "\n",
    "    # Remove equations and formulas assuming they may start with common math symbols\n",
    "    # This regex is very basic and would need to be tailored to the specific formatting of your equations\n",
    "    text = re.sub(r'\\b[\\d+-/*=]+\\b', '', text)\n",
    "\n",
    "    # Tokenize into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Join sentences to form the full text\n",
    "    full_text = ' '.join(sentences)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    full_text = re.sub(r'[.,/\"\\'\\[\\]:;()?!-]', '', full_text)  # Removes specified punctuation\n",
    "    full_text = re.sub(r'\\b\\d+\\b', '', full_text)  # Removes standalone numbers\n",
    "\n",
    "    # Strip leading and trailing whitespace that may have been left by the removals\n",
    "    processed_text = full_text.strip()\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "666135e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/pdfs/Open-Guide-to-Data-Structures-and-Algorithms.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/pdfs/Open-Guide-to-Data-Structures-and-Algorithms.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m text \u001b[38;5;241m=\u001b[39m pdf_to_text(pdf_path)\n",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m, in \u001b[0;36mpdf_to_text\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdf_to_text\u001b[39m(pdf_path):\n\u001b[0;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text(pdf_path)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pdfminer/high_level.py:120\u001b[0m, in \u001b[0;36mextract_text\u001b[0;34m(pdf_file, password, page_numbers, maxpages, caching, codec, laparams)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m laparams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     laparams \u001b[38;5;241m=\u001b[39m LAParams()\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pdf_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp, StringIO() \u001b[38;5;28;01mas\u001b[39;00m output_string:\n\u001b[1;32m    121\u001b[0m     rsrcmgr \u001b[38;5;241m=\u001b[39m PDFResourceManager()\n\u001b[1;32m    122\u001b[0m     device \u001b[38;5;241m=\u001b[39m TextConverter(rsrcmgr, output_string, codec\u001b[38;5;241m=\u001b[39mcodec,\n\u001b[1;32m    123\u001b[0m                            laparams\u001b[38;5;241m=\u001b[39mlaparams)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/pdfs/Open-Guide-to-Data-Structures-and-Algorithms.pdf'"
     ]
    }
   ],
   "source": [
    "pdf_path = '/pdfs/Open-Guide-to-Data-Structures-and-Algorithms.pdf'\n",
    "text = pdf_to_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3356c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processed = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f90df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "licensed under a Creative Commons Attribution  International License except \n",
      "where otherwise noted vii \n",
      "viii \n",
      "through the Private Academic Library Network of Indiana PALNI \n",
      "the Lilly Endowment Inc For more information about the PALSave \n",
      "bar at the bottom of the page to page forward and back textbook please send them to palsave@palniedu manager for the textbook creation process We would also like to \n",
      "thank  Amanda  Hurford  with  the  PALNI  team  for  working  with  us \n",
      "when  we  encountered  challenges  along  the  way We  owe  a  great \n",
      "debt to our reviewers Dr Joshua Kiers and Dr Aaron Boudreaux for \n",
      "their helpful suggestions and key insights that drastically improved \n",
      "our  initial  draft We  would  like  to  also  thank  Matthew  Furber  for \n",
      "offering  graphic  design  advice  as  well  as  introducing  us  to  our \n",
      "fabulous  illustrator  Mia  M  Scarlato Additionally  we  would  like \n",
      "to thank our department chair Dr Matt DeLong for his constant \n",
      "support  of  our  efforts  to  dri\n"
     ]
    }
   ],
   "source": [
    "print(text_processed[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b6a2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_text.txt', 'w', encoding = 'utf-8') as f_out:\n",
    "    f_out.write(text_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9f824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
